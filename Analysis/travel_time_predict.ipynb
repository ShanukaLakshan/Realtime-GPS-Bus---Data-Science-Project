{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"./ALL_BUS/history_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"travel_time\",\"day_of_week\",\"hour_of_day\",\"weekend\",\"rush_hour\",\"Direction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features: 'Direction'\n",
    "label_encoder = LabelEncoder()\n",
    "df['Direction'] = label_encoder.fit_transform(df['Direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>weekend</th>\n",
       "      <th>rush_hour</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.650000</td>\n",
       "      <td>3</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.133333</td>\n",
       "      <td>3</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.283333</td>\n",
       "      <td>3</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.866667</td>\n",
       "      <td>4</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   travel_time  day_of_week  hour_of_day  weekend  rush_hour  Direction\n",
       "0    52.650000            3         8.25        0          1          0\n",
       "1    57.133333            3        10.50        0          0          1\n",
       "2    63.500000            3        13.25        0          0          0\n",
       "3    57.283333            3        16.50        0          1          1\n",
       "4    53.866667            4         8.00        0          1          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAGxCAYAAAAH0U5DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVpklEQVR4nO3deYwcdNnA8WfabXe33Z4gSwvLcqkt0PIWakolHAoGqiEFxYCWSBMOq5CCiEEIhxwqEhVFo1UwNIYrGJDDpImg0ghBpGA5gulFaxu7UEOAbaFboPt7/+DtvF2fntvdTrf9fJJN5p6nv/yY+e7MLFMppZQAANhIv1oPAADsegQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkdd29YmdnZ6xcuTKGDBkSlUqlJ2cCAHpJKSVWr14do0ePjn79Nv86QbcDYeXKldHS0tLdqwMANbRixYrYf//9N3t+twNhyJAh1TsYOnRod28GANiJ2tvbo6Wlpfo8vjndDoQNbysMHTpUIABAH7O1jwf4kCIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBI6mo9APSWUkp0dHTUeow+p5QS69ati4iI+vr6qFQqNZ5o19bQ0GCN2C0JBHZbHR0dMWXKlFqPwW5uzpw50djYWOsxoMd5iwEASLyCwB5hzf98KUo/232brH8/hrxwX0RErD7y7Ij+A2o80K6n0vlBNM2/t9ZjQK/yiMkeofSr80TXHf0HWLdNKLUeAHYCbzEAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQ1NV6gI2VUqKjoyMiIhoaGqJSqdR4IgDYuXaV58Jd6hWEjo6OmDJlSkyZMqW6OACwJ9lVngt3qUAAAHYNAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAAJK6Wg+wsVJK9XBHR0cNJ2F30GUPbbS3YId5rKIXbbynSg0fu7Y5ENatWxfr1q2rHm9vb+/xYTa+/TPOOKPHb589WOcHETGw1lOwu+j8oHrQYxW9ad26dTFo0KCa3Pc2v8Xw/e9/P4YNG1b9aWlp6c25AIAa2uZXEK688sq47LLLqsfb29t7PBLq6+urh3//+99HQ0NDj94+e5aOjo7//+2u3y71bhp93Ub7yWMVPW3jx66Nnxd3tm1+1Kyvr+/1QSuVSvVwQ0NDNDY29ur9sQfZaG/BDvNYxU5SqeFjl79iAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAEldrQfYWENDQ8yZM6d6GAD2NLvKc+EuFQiVSiUaGxtrPQYA1Myu8lzoLQYAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAACSuloPADtDpfODKLUeoq9Y//6mD1NV6fyg1iNArxMI7BGa5t9b6xH6pCEv3FfrEYAa8RYDAJB4BYHdVkNDQ8yZM6fWY/Q5pZRYt25dRETU19dHpVKp8US7toaGhlqPAL1CILDbqlQq0djYWOsx+qRBgwbVegSgxrzFAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAkdd29YiklIiLa29t7bBgAoHdteN7e8Dy+Od0OhNWrV0dEREtLS3dvAgCokdWrV8ewYcM2e36lbC0hNqOzszNWrlwZQ4YMiUql0u0Bd1ft7e3R0tISK1asiKFDh9Z6nN2O9e191rh3Wd/eZ403rZQSq1evjtGjR0e/fpv/pEG3X0Ho169f7L///t29+h5j6NChNmYvsr69zxr3Luvb+6xxtqVXDjbwIUUAIBEIAEAiEHpJfX19XHfddVFfX1/rUXZL1rf3WePeZX17nzXeMd3+kCIAsPvyCgIAkAgEACARCABAIhB60M033xyVSiUuvfTS6mkdHR1x0UUXxV577RVNTU3xhS98IV5//fXaDdmHbWp9TzzxxKhUKl1+ZsyYUbsh+5jvfOc7af3GjBlTPd/+3XFbW2N7eMf9+9//jnPOOSf22muvaGxsjHHjxsW8efOq55dS4tprr41Ro0ZFY2NjnHzyybFo0aIaTtw3CIQe8uyzz8avfvWrGD9+fJfTv/GNb8Sjjz4av/vd72Lu3LmxcuXK+PznP1+jKfuuza1vRMQFF1wQbW1t1Z9bbrmlBhP2XYcffniX9XvyySer59m/PWNLaxxhD++IN998M4499tgYMGBAzJkzJ1555ZX40Y9+FCNGjKhe5pZbbonbbrstZs2aFc8880wMHjw4TjnllOjo6Kjh5Lu+bv+fFPl/a9asiWnTpsXtt98eN910U/X0t99+O37zm9/EPffcE5/+9KcjIuLOO++MsWPHxt/+9rc45phjajVyn7K59d1g0KBBse+++9Zgst1DXV3dJtfP/u05m1vjDezh7vvBD34QLS0tceedd1ZPO+igg6qHSynxk5/8JK6++uqYOnVqRET89re/jebm5njooYfi7LPP3ukz9xVeQegBF110UXzuc5+Lk08+ucvpzz33XLz//vtdTh8zZkwccMAB8fTTT+/sMfusza3vBnfffXfsvffeccQRR8SVV14Z77777k6esG9btGhRjB49Og4++OCYNm1aLF++PCLs3560uTXewB7uvkceeSQmTpwYX/ziF2OfffaJCRMmxO233149f+nSpfHaa6912cfDhg2LSZMm2cdb4RWEHXTffffF888/H88++2w677XXXouBAwfG8OHDu5ze3Nwcr7322k6asG/b0vpGRHz5y1+O1tbWGD16dLz44otxxRVXxIIFC+LBBx/cyZP2TZMmTYrZs2fHxz/+8Whra4vrr78+jjvuuHj55Zft3x6ypTUeMmSIPbyDXn311fjlL38Zl112WVx11VXx7LPPxsyZM2PgwIFx7rnnVvdqc3Nzl+vZx1snEHbAihUr4pJLLonHHnssGhoaaj3Obmdb1vfCCy+sHh43blyMGjUqTjrppFiyZEkccsghO2vUPmvKlCnVw+PHj49JkyZFa2tr3H///dHY2FjDyXYfW1rj8847zx7eQZ2dnTFx4sT43ve+FxEREyZMiJdffjlmzZoV5557bo2n69u8xbADnnvuuVi1alUcddRRUVdXF3V1dTF37ty47bbboq6uLpqbm+O9996Lt956q8v1Xn/9de83boOtre/69evTdSZNmhQREYsXL97Z4+4Whg8fHh/72Mdi8eLFse+++9q/vWDjNd4Ue3j7jBo1Kg477LAup40dO7b6Ns6Gvfrff31jH2+dQNgBJ510Urz00ksxf/786s/EiRNj2rRp1cMDBgyIP/3pT9XrLFiwIJYvXx6TJ0+u4eR9w9bWt3///uk68+fPj4gPHzTYfmvWrIklS5bEqFGj4uijj7Z/e8HGa7wp9vD2OfbYY2PBggVdTlu4cGG0trZGxIcfWNx333277OP29vZ45pln7OOtKfSoE044oVxyySXV4zNmzCgHHHBA+fOf/1zmzZtXJk+eXCZPnly7Afu4jdd38eLF5YYbbijz5s0rS5cuLQ8//HA5+OCDy/HHH1/bIfuQb37zm+WJJ54oS5cuLU899VQ5+eSTy957711WrVpVSrF/e8KW1tge3nF///vfS11dXfnud79bFi1aVO6+++4yaNCgctddd1Uvc/PNN5fhw4eXhx9+uLz44otl6tSp5aCDDipr166t4eS7PoHQw/47ENauXVu+/vWvlxEjRpRBgwaVM844o7S1tdVuwD5u4/Vdvnx5Of7448vIkSNLfX19OfTQQ8u3vvWt8vbbb9d2yD7krLPOKqNGjSoDBw4s++23XznrrLPK4sWLq+fbvztuS2tsD/eMRx99tBxxxBGlvr6+jBkzpvz617/ucn5nZ2e55pprSnNzc6mvry8nnXRSWbBgQY2m7Tt8myMAkPgMAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAlC1bNmyqFQq1e8D6I4TTzwxLr300h6bCagNgQA11lefUJ944omoVCrp2x4ffPDBuPHGG2szFNBj6mo9ALBlpZRYv3591NX1jf9cR44cWesRgB7gFQSooenTp8fcuXPjpz/9aVQqlahUKjF79uyoVCoxZ86cOProo6O+vj6efPLJWLJkSUydOjWam5ujqakpPvGJT8Tjjz9eva2rrroqJk2alO7jyCOPjBtuuKF6/I477oixY8dGQ0NDjBkzJn7xi19s99zLli2LT33qUxERMWLEiKhUKjF9+vSIyK+IHHjggXHTTTfFV77ylWhqaorW1tZ45JFH4j//+U9MnTo1mpqaYvz48TFv3rwu9/Hkk0/GcccdF42NjdHS0hIzZ86Md955Z7tnBbqpxl8WBXu0t956q0yePLlccMEFpa2trbS1tZXHH3+8REQZP358+eMf/1gWL15c3njjjTJ//vwya9as8tJLL5WFCxeWq6++ujQ0NJR//etfpZRSXn755RIRXb6NccNpixYtKqWUctddd5VRo0aVBx54oLz66qvlgQceKCNHjiyzZ88upZSydOnSEhHlH//4xxbn/uCDD8oDDzxQIqIsWLCgtLW1lbfeequUkr/RtLW1tYwcObLMmjWrLFy4sHzta18rQ4cOLaeeemq5//77y4IFC8rpp59exo4dWzo7O0spH36V9+DBg8utt95aFi5cWJ566qkyYcKEMn369J5aemArBALU2H8/of7lL38pEVEeeuihrV738MMPLz/72c+qx4888shyww03VI9feeWVZdKkSdXjhxxySLnnnnu63MaNN95YJk+eXErZ9kDYeM4333xzi/+e1tbWcs4551SPt7W1lYgo11xzTfW0p59+ukRE9aukzzvvvHLhhRd2ud2//vWvpV+/fmXt2rVbnQ3Ycd5igF3UxIkTuxxfs2ZNXH755TF27NgYPnx4NDU1xT//+c9Yvnx59TLTpk2Le+65JyI+/OzCvffeG9OmTYuIiHfeeSeWLFkS5513XjQ1NVV/brrppliyZEmv/lvGjx9fPdzc3BwREePGjUunrVq1KiIiXnjhhZg9e3aXOU855ZTo7OyMpUuX9uqswIf6xqeeYA80ePDgLscvv/zyeOyxx+KHP/xhHHroodHY2BhnnnlmvPfee9XLfOlLX4orrrginn/++Vi7dm2sWLEizjrrrIj4MDAiIm6//fb0WYX+/fv36r9lwIAB1cOVSmWzp3V2dlZn/epXvxozZ85Mt3XAAQf05qjA/xEIUGMDBw6M9evXb/VyTz31VEyfPj3OOOOMiPjwSXTZsmVdLrP//vvHCSecEHfffXesXbs2PvOZz8Q+++wTER/+lj569Oh49dVXq68q7OjcEbFNs2+vo446Kl555ZU49NBDe/y2gW0jEKDGDjzwwHjmmWdi2bJl0dTUVP0t+r999KMfjQcffDBOO+20qFQqcc0112zystOmTYvrrrsu3nvvvbj11lu7nHf99dfHzJkzY9iwYXHqqafGunXrYt68efHmm2/GZZddtl1zt7a2RqVSiT/84Q/x2c9+NhobG6OpqWm7bmNzrrjiijjmmGPi4osvjvPPPz8GDx4cr7zySjz22GPx85//vEfuA9gyn0GAGrv88sujf//+cdhhh8VHPvKRLp8p2NiPf/zjGDFiRHzyk5+M0047LU455ZQ46qij0uXOPPPMeOONN+Ldd9+N008/vct5559/ftxxxx1x5513xrhx4+KEE06I2bNnx0EHHbTdc++3335x/fXXx7e//e1obm6Oiy++eLtvY3PGjx8fc+fOjYULF8Zxxx0XEyZMiGuvvTZGjx7dY/cBbFmllFJqPQQAsGvxCgIAkAgEYJNmzJjR5c8MN/6ZMWNGrccDepm3GIBNWrVqVbS3t2/yvKFDh1b/OgLYPQkEACDxFgMAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBI/he+VnApx8FaVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the distribution of 'travel_time' using a box plot\n",
    "sns.boxplot(x=df['travel_time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores for 'travel_time'\n",
    "z_scores = zscore(df['travel_time'])\n",
    "\n",
    "# Find and remove outliers based on z-score (threshold = 2)\n",
    "outlier_indices = (z_scores > 2) | (z_scores < -2)\n",
    "df = df[~outlier_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df[['hour_of_day', 'day_of_week', 'Direction', 'rush_hour']]\n",
    "y = df['travel_time']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 30.49702645709133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['travel_time_prediction_model.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict travel_time on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error to evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Save the trained model for future use\n",
    "joblib.dump(model, 'travel_time_prediction_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 24.688444601348998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gradient_boosting_travel_time_model.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize and train the Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict travel_time on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error to evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Save the trained model for future use\n",
    "joblib.dump(model, 'gradient_boosting_travel_time_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean Squared Error (Best Model): 24.370356804297057\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set the hyperparameters grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Predict travel_time on the test set using the best model\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error to evaluate the best model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error (Best Model):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "66/66 [==============================] - 1s 4ms/step - loss: 1460.7134 - val_loss: 216.1836\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 175.9858 - val_loss: 181.0675\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 159.7072 - val_loss: 168.0415\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 149.9926 - val_loss: 161.2279\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 140.3651 - val_loss: 146.9889\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 129.4929 - val_loss: 133.9020\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 117.6893 - val_loss: 122.9669\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 105.1084 - val_loss: 106.4598\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 93.2499 - val_loss: 92.6586\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 81.4768 - val_loss: 79.7849\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 68.0960 - val_loss: 69.5922\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 56.3943 - val_loss: 53.7413\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 46.7700 - val_loss: 44.2770\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 39.2590 - val_loss: 37.1674\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 35.0472 - val_loss: 33.3163\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 32.1652 - val_loss: 32.2882\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 31.2879 - val_loss: 31.8919\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 31.2990 - val_loss: 30.7386\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 29.8244 - val_loss: 30.4332\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 29.9328 - val_loss: 29.8666\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 29.9519 - val_loss: 29.7808\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 29.4749 - val_loss: 29.5854\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.8976 - val_loss: 29.3848\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 29.2268 - val_loss: 29.7811\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.9525 - val_loss: 29.8373\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.7589 - val_loss: 29.2759\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.6098 - val_loss: 29.3270\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.9387 - val_loss: 29.7204\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.1450 - val_loss: 30.2404\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.4303 - val_loss: 29.5570\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.3622 - val_loss: 29.0745\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.3132 - val_loss: 31.3910\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.6802 - val_loss: 29.0079\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.9105 - val_loss: 31.0371\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.1648 - val_loss: 29.8957\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.0858 - val_loss: 31.1999\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.2035 - val_loss: 31.1865\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.0472 - val_loss: 28.6355\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.7474 - val_loss: 29.3527\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.7096 - val_loss: 28.8686\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.9800 - val_loss: 28.4440\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.4431 - val_loss: 29.6733\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.6094 - val_loss: 28.4653\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.5284 - val_loss: 29.0847\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.5825 - val_loss: 28.9990\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.8064 - val_loss: 28.3949\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.3697 - val_loss: 28.2017\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.9347 - val_loss: 30.3138\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9281 - val_loss: 31.9413\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.4940 - val_loss: 29.1863\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.2908 - val_loss: 29.6157\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9324 - val_loss: 28.2836\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.2567 - val_loss: 29.3051\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.7690 - val_loss: 28.0455\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.6738 - val_loss: 28.7751\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.3642 - val_loss: 27.8314\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.1502 - val_loss: 27.9571\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.7870 - val_loss: 28.0986\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 28.2564 - val_loss: 27.7191\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.7112 - val_loss: 28.0187\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.7422 - val_loss: 29.2466\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.0477 - val_loss: 30.2256\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9001 - val_loss: 28.2598\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.7307 - val_loss: 27.9970\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.3813 - val_loss: 28.6756\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.0173 - val_loss: 27.9973\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.2629 - val_loss: 27.8295\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.5207 - val_loss: 28.8374\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6216 - val_loss: 28.3581\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.4800 - val_loss: 28.5234\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9816 - val_loss: 28.4257\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6173 - val_loss: 27.9984\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6487 - val_loss: 29.9210\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.7358 - val_loss: 28.3709\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.2538 - val_loss: 28.7450\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.8777 - val_loss: 28.3429\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6538 - val_loss: 29.0397\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9456 - val_loss: 28.6996\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.7579 - val_loss: 27.6435\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.0236 - val_loss: 27.7567\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9366 - val_loss: 27.2991\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.8053 - val_loss: 28.0006\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.3930 - val_loss: 27.4653\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6069 - val_loss: 28.3564\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.8248 - val_loss: 27.9435\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.3571 - val_loss: 29.3865\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.5420 - val_loss: 27.5112\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.0819 - val_loss: 28.6833\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6453 - val_loss: 27.9024\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.9151 - val_loss: 28.1252\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 27.5478 - val_loss: 27.5520\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.8271 - val_loss: 27.9658\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.7052 - val_loss: 27.5907\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.3156 - val_loss: 27.3398\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6941 - val_loss: 27.2638\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.2958 - val_loss: 27.4706\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.4938 - val_loss: 27.4269\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.2537 - val_loss: 28.3379\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.7936 - val_loss: 27.8099\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 26.6451 - val_loss: 29.4689\n",
      "21/21 [==============================] - 0s 2ms/step\n",
      "Mean Squared Error (Neural Network): 28.848099718748486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "features = ['hour_of_day', 'day_of_week', 'Direction', 'rush_hour']\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with 1 neuron for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error (Neural Network):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
